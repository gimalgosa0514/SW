{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gimalgosa0514/SW/blob/main/DeepFashion_Try_On_Look_For_You.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CCSQIBMAYYZ"
      },
      "source": [
        "# DeepFashion Try-On\n",
        "\n",
        "Towards Photo-Realistic Virtual Try-On by Adaptively Generating↔Preserving Image Content, CVPR'20.\n",
        "\n",
        "![](https://github.com/switchablenorms/DeepFashion_Try_On/raw/master/images/tryon.png)\n",
        "\n",
        "## For inferencing ACGPN!\n",
        "\n",
        "ACGPN repo: https://github.com/switchablenorms/DeepFashion_Try_On\n",
        "\n",
        "This notebook is hard coded for inferencing one image at a time.\n",
        "\n",
        "Notebook by [Levin Dabhi](https://levindabhi.github.io/)\n",
        "\n",
        "```\n",
        "author = {Yang, Han and Zhang, Ruimao and Guo, Xiaobao and Liu, Wei and Zuo, Wangmeng and Luo, Ping},\n",
        "title = {Towards Photo-Realistic Virtual Try-On by Adaptively Generating-Preserving Image Content},\n",
        "booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
        "month = {June},\n",
        "year = {2020}\n",
        "}\n",
        "\n",
        "@inproceedings{ge2021disentangled,\n",
        "  title={Disentangled Cycle Consistency for Highly-realistic Virtual Try-On},\n",
        "  author={Ge, Chongjian and Song, Yibing and Ge, Yuying and Yang, Han and Liu, Wei and Luo, Ping},\n",
        "  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n",
        "  pages={16928--16937},\n",
        "  year={2021}\n",
        "}\n",
        "\n",
        "@inproceedings{yang2022full,\n",
        "title = {Full-Range Virtual Try-On With Recurrent Tri-Level Transform},\n",
        "author = {Yang, Han and Yu, Xinrui and Liu, Ziwei},\n",
        "booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n",
        "pages = {3460--3469}\n",
        "year = {2022}\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WJtP2PfBcPN"
      },
      "source": [
        "## ACGPN\n",
        "\n",
        "- Original: https://github.com/levindabhi/ACGPN.git\n",
        "- Modified: https://github.com/kairess/ACGPN.git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVm5QFBMDBbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c35519-0c4f-44aa-deba-970d2f8dbcfe"
      },
      "source": [
        "!git clone https://github.com/kairess/ACGPN.git    #git을 이용해서 저 URL에 있는 코드를 내려받아서 로컬 환경으로 복제한다.\n",
        "%cd ACGPN     \n",
        "#현재 작업 디렉토리를 ACGPN 디렉토리로 바꾼다. 여기서 ACGPN은 누끼 딴 옷 이미지와 사람 이미지를 합성하는 모델로 추정됨"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ACGPN'...\n",
            "remote: Enumerating objects: 165, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 165 (delta 21), reused 19 (delta 18), pack-reused 141\u001b[K\n",
            "Receiving objects: 100% (165/165), 303.15 KiB | 3.00 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "/content/ACGPN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "-nBzTaWmcTK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --no-cache-dir gdown --pre -qq     #gdown이라는 Python 패키지를 설치하는 명령어입니다. gdown패키지는 구글 드라이브에서 파일을 다운로드하는데 사용된다.\n",
        "#--no-cache-dir 옵션은 패키지 캐시를 사용하지 않도록 지정합니다. \n",
        "#--pre 옵션은 미리 릴리스 된 패키지뿐만 아니라 베타 또는 릴리스 전 버전의 패키지도 설치할 수 있도록 해줍니다\n",
        "#-qq 옵션은 출력 메시지를 최소화하므로 설치 과정에서 출력되는 메시지가 적어집니다.\n",
        "\n",
        "!pip install ninja -qq   #ninja라는 빌드 시스템을 설치하는 명령어입니다. \n",
        "#ninja는 C++ 등의 프로그래밍 언어로 작성된 프로젝트에서 빌드 시스템으로 사용되는 빌드 도구입니다.\n",
        "#ninja는 build.ninja 라는 파일 형식을 사용하여 빌드 과정을 기술합니다. \n",
        "#이 파일에는 각 빌드 타겟과 해당 타겟이 의존하는 파일, 그리고 빌드 명령어 등이 기술되어 있습니다. \n",
        "#이렇게 작성된 build.ninja 파일은 ninja 명령어를 실행하여 빌드를 수행할 수 있습니다."
      ],
      "metadata": {
        "id": "GEj3cTepGTcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed60c758-b826-4ab9-c093-8949d1bb8fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/146.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQwI--uhoH6R"
      },
      "source": [
        "import gdown #gdown 라이브러리를 사용하여 Google Drive에 저장된 모델 가중치 파일을 다운로드\n",
        "import numpy as np #NumPy는 파이썬에서 사용되는 대규모 다차원 배열 및 행렬 연산을 위한 라이브러리\n",
        "from PIL import Image #Image 모듈은 이미지 파일을 열고 읽어들이고, 크기를 조절하고, 필터를 적용하고, 이미지를 저장하는 등의 다양한 작업을 수행\n",
        "import IPython\n",
        "import gdown\n",
        "import os #운영체제와 상호작용\n",
        "import sys \n",
        "import time\n",
        "\n",
        "from predict_pose import generate_pose_keypoints \n",
        "#generate_pose_keypoints 함수를 사용하여 이미지에서 사람의 포즈를 추론하고, 추론된 포즈의 키포인트 좌표를 반환합니다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Ll7LIW1kGw"
      },
      "source": [
        "!mkdir Data_preprocessing/test_color\n",
        "!mkdir Data_preprocessing/test_colormask\n",
        "!mkdir Data_preprocessing/test_edge\n",
        "!mkdir Data_preprocessing/test_img\n",
        "!mkdir Data_preprocessing/test_label\n",
        "!mkdir Data_preprocessing/test_mask\n",
        "!mkdir Data_preprocessing/test_pose\n",
        "!mkdir inputs\n",
        "!mkdir inputs/img\n",
        "!mkdir inputs/cloth\n",
        "\n",
        "#디렉토리 생성"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbGDB31KrKHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8ab9050-e71b-4051-bf6c-748a0bf0e883"
      },
      "source": [
        "!git clone https://github.com/levindabhi/Self-Correction-Human-Parsing-for-ACGPN.git  #사람의 포즈를 예측하고 상의,하의,악세사리등을 인식할 수 있는 모델\n",
        "!git clone https://github.com/levindabhi/U-2-Net.git #옷 누끼 따는 모델"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Self-Correction-Human-Parsing-for-ACGPN'...\n",
            "remote: Enumerating objects: 769, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 769 (delta 72), reused 62 (delta 62), pack-reused 658\u001b[K\n",
            "Receiving objects: 100% (769/769), 3.80 MiB | 17.68 MiB/s, done.\n",
            "Resolving deltas: 100% (189/189), done.\n",
            "Cloning into 'U-2-Net'...\n",
            "remote: Enumerating objects: 822, done.\u001b[K\n",
            "remote: Counting objects: 100% (822/822), done.\u001b[K\n",
            "remote: Compressing objects: 100% (439/439), done.\u001b[K\n",
            "remote: Total 822 (delta 389), reused 793 (delta 379), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (822/822), 30.71 MiB | 40.11 MiB/s, done.\n",
            "Resolving deltas: 100% (389/389), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 사전학습 모델 다운로드"
      ],
      "metadata": {
        "id": "vCjptBAJiGrI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 포즈 예측 모델"
      ],
      "metadata": {
        "id": "5XNAZwQziKHe"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8hYM6XqCnxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b10521c8-3d04-48f4-c5e1-c6a512813dd8"
      },
      "source": [
        "!gdown 1hOHMFHEjhoJuLEQY0Ndurn5hfiA9mwko -O pose/pose_iter_440000.caffemodel\n",
        "#1hOHMFHEjhoJuLEQY0Ndurn5hfiA9mwko ID를 가진 파일이 pose/pose_iter_440000.caffemodel 경로에 다운로드됩니다. 이 명령어를 실행하기 위해서는 gdown 패키지가 미리 설치되어 있어야 합니다.\n",
        "#포즈 예측 모델인듯"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1hOHMFHEjhoJuLEQY0Ndurn5hfiA9mwko\n",
            "From (redirected): https://drive.google.com/uc?id=1hOHMFHEjhoJuLEQY0Ndurn5hfiA9mwko&confirm=t&uuid=0c157d22-f8c1-4083-aa1b-0ddf64f90924\n",
            "To: /content/ACGPN/pose/pose_iter_440000.caffemodel\n",
            "100% 209M/209M [00:08<00:00, 24.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 휴먼 세그멘테이션 마스크 생성 모델"
      ],
      "metadata": {
        "id": "FHHxH87diN7D"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hSJI347rZtQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "d84dedcc-8079-4b7c-c7b5-16e9ee91ddf6"
      },
      "source": [
        "gdown.download('https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH', 'lip_final.pth', quiet=False)\n",
        "#저 url 주소에 있는 파일을 다운로드해서 이름을 lip_final.pth로 저장한다. quiet를 false로 지정하면 다운로드 진행상황을 알려준다.\n",
        "#gdown은 google drive에 대용량 파일을 다운로드 할 수 있게 한다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH\n",
            "From (redirected): https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH&confirm=t&uuid=6820da67-b4a9-419b-8ab2-32fd4e9dc749\n",
            "To: /content/ACGPN/lip_final.pth\n",
            "100%|██████████| 267M/267M [00:10<00:00, 25.0MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lip_final.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### U2Net 모델\n",
        "\n",
        "옷 마스크 추출 모델"
      ],
      "metadata": {
        "id": "QhpO0t1wio9_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzy8poZT6pcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b41629e-7938-497b-8553-41ba3b45c857"
      },
      "source": [
        "%cd U-2-Net\n",
        "!mkdir saved_models\n",
        "!mkdir saved_models/u2net\n",
        "!mkdir saved_models/u2netp\n",
        "\n",
        "!gdown 1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy -O saved_models/u2netp/u2netp.pth\n",
        "!gdown 1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ -O saved_models/u2net/u2net.pth\n",
        "\n",
        "import u2net_load #u2net_load 모듈은 U-2-Net 모델을 로드하고 초기화하는 함수를 제공합니다. \n",
        "import u2net_run #u2net_run 모듈은 입력 이미지를 U-2-Net 모델에 전달하여 전경과 배경을 분리하는 함수를 제공합니다. \n",
        "\n",
        "u2net = u2net_load.model(model_name='u2netp') #U2Net 모델 불러오기\n",
        "\n",
        "%cd .. #이전 작업 폴더로 돌아감"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ACGPN/U-2-Net\n",
            "mkdir: cannot create directory ‘saved_models’: File exists\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy\n",
            "To: /content/ACGPN/U-2-Net/saved_models/u2netp/u2netp.pth\n",
            "100% 4.68M/4.68M [00:00<00:00, 203MB/s]\n",
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ\n",
            "From (redirected): https://drive.google.com/uc?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ&confirm=t&uuid=50508f84-6c84-455a-b30f-bd762a84cb98\n",
            "To: /content/ACGPN/U-2-Net/saved_models/u2net/u2net.pth\n",
            "100% 176M/176M [00:00<00:00, 199MB/s]\n",
            "...load U2NEP---4.7 MB\n",
            "[Errno 2] No such file or directory: '.. #이전 작업 폴더로 돌아감'\n",
            "/content/ACGPN/U-2-Net\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ACGPN 모델"
      ],
      "metadata": {
        "id": "5ycY0WVmjD_f"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1VknOqswSTW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c6c6ff0-0ff0-4d1b-c522-c2ca8bf3bd8c"
      },
      "source": [
        "!mkdir checkpoints\n",
        "\n",
        "gdown.download('https://drive.google.com/uc?id=1UWT6esQIU_d4tUm8cjxDKMhB8joQbrFx', output='checkpoints/ACGPN_checkpoints.zip', quiet=False) #저 url 파일을 다운받아서 checkpoints 디렉토리에 ACGPN_checkopoints.zip으로 저장한다.\n",
        "\n",
        "!unzip checkpoints/ACGPN_checkpoints.zip -d checkpoints #ACGPN_checkpoints.zip을 압축해제한다.\n",
        "#이 작업은 ACGPN 모델의 학습된 가중치를 다운로드하고, 모델을 사용하여 이미지를 처리할 수 있도록 하는 데 필요합니다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1UWT6esQIU_d4tUm8cjxDKMhB8joQbrFx\n",
            "From (redirected): https://drive.google.com/uc?id=1UWT6esQIU_d4tUm8cjxDKMhB8joQbrFx&confirm=t&uuid=15ccca49-84aa-4ef1-9364-1de65dddde5e\n",
            "To: /content/ACGPN/U-2-Net/checkpoints/ACGPN_checkpoints.zip\n",
            "100%|██████████| 524M/524M [00:02<00:00, 224MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  checkpoints/ACGPN_checkpoints.zip\n",
            "   creating: checkpoints/label2city/\n",
            "  inflating: checkpoints/label2city/latest_net_G.pth  \n",
            "  inflating: checkpoints/label2city/latest_net_G1.pth  \n",
            "  inflating: checkpoints/label2city/latest_net_G2.pth  \n",
            "  inflating: checkpoints/label2city/latest_net_U.pth  \n",
            "  inflating: checkpoints/label2city/opt.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VITON 데이터셋\n",
        "\n",
        "https://drive.google.com/uc?id=1tE7hcVFm8Td8kRh5iYRBSDFdvZIkbUIR\n",
        "\n",
        "## AI허브 패션 데이터셋\n",
        "\n",
        "https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=78\n",
        "\n",
        "![](https://aihub.or.kr/web-nas/aihub21/files/public/inline-images/65_%ED%8C%A8%EC%85%98%EC%83%81%ED%92%88%EB%B0%8F%EC%B0%A9%EC%9A%A9%EC%98%81%EC%83%81_%EB%8C%80%ED%91%9C%EB%8F%84.PNG)"
      ],
      "metadata": {
        "id": "g034eSWgbi4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전처리"
      ],
      "metadata": {
        "id": "r3jABay-kHWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 옷 마스크 추출"
      ],
      "metadata": {
        "id": "9tqSGFNBhj9k"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBXPbfF5XYRB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "756a9096-896f-46a7-dcd4-fdc2139202e7"
      },
      "source": [
        "sorted(os.listdir('inputs/cloth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-d46badbec747>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inputs/cloth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'inputs/cloth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm-9Up6z0Zpg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "9b6ef26b-c114-4766-94e6-f23e71bed7df"
      },
      "source": [
        "cloth_name = f'cloth_{int(time.time())}.png'\n",
        "\n",
        "cloth_path = os.path.join('inputs/cloth', sorted(os.listdir('inputs/cloth'))[0])\n",
        "cloth = Image.open(cloth_path)\n",
        "cloth = cloth.resize((192, 256), Image.BICUBIC).convert('RGB')\n",
        "cloth.save(os.path.join('Data_preprocessing/test_color', cloth_name))\n",
        "\n",
        "u2net_run.infer(u2net, 'Data_preprocessing/test_color', 'Data_preprocessing/test_edge')\n",
        "\n",
        "Image.open(f'Data_preprocessing/test_edge/{cloth_name}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3775082cace7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcloth_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'cloth_{int(time.time())}.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcloth_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inputs/cloth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inputs/cloth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcloth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloth_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcloth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m192\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBICUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'inputs/cloth'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 포즈, 세그멘테이션"
      ],
      "metadata": {
        "id": "N7WqDchhhgVO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj8vmpyXX0tx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "88bfa72d-2591-47ef-e858-856108377d10"
      },
      "source": [
        "sorted(os.listdir('inputs/img'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-880433f637d5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inputs/img'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'inputs/img'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3aHah45D655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "c76ef2c0-7cae-45d8-9ac9-361c63655c10"
      },
      "source": [
        "img_name = f'img_{int(time.time())}.png'\n",
        "\n",
        "img_path = os.path.join('inputs/img', sorted(os.listdir('inputs/img'))[0])\n",
        "img = Image.open(img_path)\n",
        "img = img.resize((192,256), Image.BICUBIC)\n",
        "\n",
        "img_path = os.path.join('Data_preprocessing/test_img', img_name)\n",
        "img.save(img_path)\n",
        "\n",
        "!python3 Self-Correction-Human-Parsing-for-ACGPN/simple_extractor.py --dataset 'lip' --model-restore 'lip_final.pth' --input-dir 'Data_preprocessing/test_img' --output-dir 'Data_preprocessing/test_label'\n",
        "\n",
        "pose_path = os.path.join('Data_preprocessing/test_pose', img_name.replace('.png', '_keypoints.json'))\n",
        "generate_pose_keypoints(img_path, pose_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-ce108fc5521e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'img_{int(time.time())}.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inputs/img'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inputs/img'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m192\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBICUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'inputs/img'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 추론"
      ],
      "metadata": {
        "id": "SdbIgthWkJFK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgMi912KAUNs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "cfd23d40-65f7-451b-918d-e32b709993fa"
      },
      "source": [
        "!rm -rf Data_preprocessing/test_pairs.txt\n",
        "with open('Data_preprocessing/test_pairs.txt', 'w') as f:\n",
        "    f.write(f'{img_name} {cloth_name}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-4bfb372e87a1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -rf Data_preprocessing/test_pairs.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data_preprocessing/test_pairs.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{img_name} {cloth_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data_preprocessing/test_pairs.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIcoP4ll14Ia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b4aa9a-9b64-4600-f315-5d1a14cb0265"
      },
      "source": [
        "!python test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/ACGPN/U-2-Net/ACGPN/U-2-Net/test.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결과"
      ],
      "metadata": {
        "id": "IrPaN8nYlnYc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5FWfCeyJ8VL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "69e4cd7b-eb16-4ee1-f79c-71b9f41fec70"
      },
      "source": [
        "output_grid = np.concatenate([\n",
        "    np.array(Image.open(f'Data_preprocessing/test_img/{img_name}')),\n",
        "    np.array(Image.open(f'Data_preprocessing/test_color/{cloth_name}')),\n",
        "    np.array(Image.open(f'results/test/try-on/{img_name}'))\n",
        "], axis=1)\n",
        "\n",
        "image_grid = Image.fromarray(output_grid)\n",
        "\n",
        "image_grid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-c4110378e717>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m output_grid = np.concatenate([\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Data_preprocessing/test_img/{img_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Data_preprocessing/test_color/{cloth_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'results/test/try-on/{img_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ], axis=1)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2975\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data_preprocessing/test_img/img_1683093878.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wq0TzJAIliUk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}